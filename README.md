
# 📰 پروژه دسته‌بندی خودکار متون خبری (متن‌کاوی فارسی)

در این پروژه، با استفاده از تکنیک‌های متن‌کاوی و یادگیری ماشین، اخبار فارسی از سایت خبرگزاری ایسنا جمع‌آوری و به دسته‌های مختلف (ورزشی، سیاسی، علمی و فرهنگی) طبقه‌بندی شده‌اند.

---

## 📌 مراحل انجام پروژه:

### 1. جمع‌آوری داده‌ها (Web Scraping)
با استفاده از `requests` و `BeautifulSoup` اطلاعات خبری (عنوان، لینک، متن کامل) از سایت ISNA.ir استخراج شده‌اند.

### 2. پیش‌پردازش متن (Text Preprocessing)
استفاده از کتابخانه `hazm` برای:
- نرمال‌سازی
- حذف علائم نگارشی
- حذف کلمات توقف (stopwords)
- ریشه‌یابی (stemming)

### 3. تبدیل متن به ویژگی عددی (TF-IDF)

### 4. مدل‌سازی با SVM
مدل Support Vector Machine (SVM) بهترین عملکرد را نسبت به Naive Bayes و Logistic Regression ارائه داده است.

### 5. تست با متن دلخواه
با وارد کردن یک خبر جدید، مدل دسته آن را پیش‌بینی می‌کند (مثلاً سیاسی یا ورزشی).

---

## 🧪 ابزارها و کتابخانه‌ها:
- Python 3
- BeautifulSoup
- Hazm
- scikit-learn
- Pandas

---

## 📁 ساختار فایل‌ها:
```bash
├── news_dataset.csv                # دیتاست خام از اسکرپ
├── news_dataset_processed.csv      # دیتاست تمیزشده و پیش‌پردازش‌شده
├── news_text_classification_project.ipynb  # فایل نوت‌بوک مرحله‌به‌مرحله
└── README.md
```

---

## 🔍 نمونه تست:
```python
text = "سخنگوی دولت از مذاکرات جدید در زمینه سیاست خارجی خبر داد."
print(predict_category(text))
# خروجی: سیاسی
```

---

## 👤 توسعه‌دهنده:
[نام شما] - پروژه نمونه‌کار برای NLP و متن‌کاوی فارسی

---

## 📌 مناسب برای:
- آموزش پروژه‌محور یادگیری ماشین
- نمونه‌کار فریلنسری
- دسته‌بندی متون فارسی

---

## 📎 لایسنس:
MIT License
